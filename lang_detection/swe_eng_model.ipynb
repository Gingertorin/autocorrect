{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out English & Swedish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>language_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4325196</td>\n",
       "      <td>por</td>\n",
       "      <td>você viu o meu telefone? poxa, pior que não.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11116788</td>\n",
       "      <td>eng</td>\n",
       "      <td>ziri and rima should nevr have eaten at that r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7380358</td>\n",
       "      <td>eng</td>\n",
       "      <td>mary is married now, isnt she?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11905621</td>\n",
       "      <td>swe</td>\n",
       "      <td>alla santiagos planer misslyckades.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10211752</td>\n",
       "      <td>spa</td>\n",
       "      <td>vosotras sois la razón por la que vine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>4371134</td>\n",
       "      <td>swe</td>\n",
       "      <td>tom kommer hit så gott som varje dag.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>11938611</td>\n",
       "      <td>swe</td>\n",
       "      <td>undantag kan gälla i vissa fall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>3807254</td>\n",
       "      <td>swe</td>\n",
       "      <td>ett gott samvete är bästa huvudkudden.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>3049523</td>\n",
       "      <td>eng</td>\n",
       "      <td>the experiments have been being carried out si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>4530529</td>\n",
       "      <td>ita</td>\n",
       "      <td>alcuni dei tuoi video sono stati bloccati.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id language_code  \\\n",
       "0         4325196           por   \n",
       "1        11116788           eng   \n",
       "2         7380358           eng   \n",
       "3        11905621           swe   \n",
       "4        10211752           spa   \n",
       "...           ...           ...   \n",
       "8995      4371134           swe   \n",
       "8996     11938611           swe   \n",
       "8997      3807254           swe   \n",
       "8998      3049523           eng   \n",
       "8999      4530529           ita   \n",
       "\n",
       "                                               sentence  \n",
       "0          você viu o meu telefone? poxa, pior que não.  \n",
       "1     ziri and rima should nevr have eaten at that r...  \n",
       "2                        mary is married now, isnt she?  \n",
       "3                   alla santiagos planer misslyckades.  \n",
       "4               vosotras sois la razón por la que vine.  \n",
       "...                                                 ...  \n",
       "8995              tom kommer hit så gott som varje dag.  \n",
       "8996                   undantag kan gälla i vissa fall.  \n",
       "8997             ett gott samvete är bästa huvudkudden.  \n",
       "8998  the experiments have been being carried out si...  \n",
       "8999         alcuni dei tuoi video sono stati bloccati.  \n",
       "\n",
       "[9000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_filtered = df[df['language_code'].isin(['eng', 'swe'])]\n",
    "\n",
    "# Get all unique languages except English and Swedish\n",
    "other_languages = df[~df['language_code'].isin(['eng', 'swe'])]['language_code'].unique()\n",
    "\n",
    "# Calculate how many samples per language (ensuring equal distribution)\n",
    "num_samples_per_lang = 3000 // len(other_languages)  # Divide equally\n",
    "\n",
    "# Select equal samples from each remaining language\n",
    "df_other = df[df['language_code'].isin(other_languages)].groupby('language_code').sample(n=num_samples_per_lang, random_state=42)\n",
    "\n",
    "# Combine both datasets\n",
    "df_final = pd.concat([df_filtered, df_other])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_final = df_final.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to add noise to the data\n",
    "### Function to get a neighboring key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QWERTY keyboard adjacency dictionary\n",
    "KEYBOARD_ADJACENCY = {\n",
    "    'a': \"qwszåä\", 'b': \"vghn \", 'c': \"xdfv \", 'd': \"ersfxc\", 'e': \"wrsd\", 'f': \"rtdgcv\",\n",
    "    'g': \"tyfhvb\", 'h': \"yugjbn\", 'i': \"uojk\", 'j': \"uikmhn\", 'k': \"ijolm,\", 'l': \"kopöä-\", 'm': \"njk,.\", \n",
    "    'n': \"bhjm \", 'o': \"ipklö\", 'p': \"olå\", 'q': \"wa\", 'r': \"etdf\", 's': \"awedxzå\", 't': \"ryfgh\", 'u': \"yiokj\",\n",
    "    'v': \"cfgb \", 'w': \"qeas\", 'x': \"zsdc \", 'y': \"tughj\", 'z': \"asx\", 'å': \"äp\", 'ä': \"åö\", 'ö': \"äpl-\",\n",
    "    '1': \"2q\", '2': \"13wq\", '3': \"24erw\", '4': \"35rte\", '5': \"46yt\", '6': \"57yu\", '7': \"68ui\", '8': \"79io\", \n",
    "    '9': \"80op\", '0': \"9p-\", '-': \"öä.\", ',': \"mkl.\", '.': \",-/\",\n",
    "    ' ': \"xcvbnm,.-\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_adjacent_key(char):\n",
    "    \"\"\"Returns a neighboring key with higher probability for close typos.\"\"\"\n",
    "    if char in KEYBOARD_ADJACENCY:\n",
    "        return random.choice(KEYBOARD_ADJACENCY[char])\n",
    "    return char  # If not found, return the same char\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency-Based Typo Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency-based typo mapping (more common mistakes occur more often)\n",
    "COMMON_TYPOS = {\n",
    "    'å': [('a', 0.7), ('ä', 0.2), ('p', 0.1)],\n",
    "    'ä': [('a', 0.5), ('ö', 0.3), ('å', 0.2)],\n",
    "    'ö': [('o', 0.6), ('ä', 0.3), ('l', 0.1)],\n",
    "    'e': [('r', 0.3), ('w', 0.2), ('d', 0.1)],\n",
    "    'r': [('e', 0.4), ('t', 0.2), ('f', 0.1)],\n",
    "    'o': [('i', 0.5), ('p', 0.3), ('ö', 0.2)],\n",
    "    'n': [('m', 0.4), ('b', 0.2), (' ', 0.1)],\n",
    "    'm': [('n', 0.5), (',', 0.2), (' ', 0.2)],\n",
    "    ',': [('m', 0.4), ('k', 0.3), ('.', 0.2), ('l', 0.1)],\n",
    "    '.': [(',', 0.5), ('-', 0.3), ('/', 0.2)],\n",
    "    '-': [('.', 0.5), ('ö', 0.3), ('ä', 0.2)],\n",
    "    ' ': [('m', 0.3), ('n', 0.3), (',', 0.2), ('.', 0.2)],\n",
    "}\n",
    "\n",
    "# Function to get a frequent typo replacement\n",
    "def get_common_typo(char):\n",
    "    \"\"\"Returns a common typo with probability-based mistakes.\"\"\"\n",
    "    if char in COMMON_TYPOS:\n",
    "        choices, weights = zip(*COMMON_TYPOS[char]) \n",
    "        return random.choices(choices, weights=weights, k=1)[0]\n",
    "    return char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_characters(word):\n",
    "    \"\"\"Swap two adjacent characters with a higher probability for closer keys.\"\"\"\n",
    "    if len(word) > 1:\n",
    "        pos = random.randint(0, len(word) - 2)\n",
    "        # Swap adjacent characters with 80% probability\n",
    "        if random.random() < 0.8:\n",
    "            return word[:pos] + word[pos + 1] + word[pos] + word[pos + 2:]\n",
    "    return word\n",
    "\n",
    "\n",
    "def delete_character(word):\n",
    "    \"\"\"Randomly delete a character.\"\"\"\n",
    "    if len(word) > 1:\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        return word[:pos] + word[pos + 1:]\n",
    "    return word\n",
    "\n",
    "\n",
    "def insert_character(word):\n",
    "    \"\"\"Insert a random adjacent character with higher probability for closer keys.\"\"\"\n",
    "    pos = random.randint(0, len(word))\n",
    "    base_char = word[pos - 1] if pos > 0 else random.choice(list(KEYBOARD_ADJACENCY.keys()))\n",
    "    random_char = get_adjacent_key(base_char)  # More likely to insert adjacent key\n",
    "    return word[:pos] + random_char + word[pos:]\n",
    "\n",
    "\n",
    "def replace_character(word):\n",
    "    \"\"\"Replace a character with a nearby key instead of a fully random key.\"\"\"\n",
    "    if len(word) > 0:\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        random_char = get_adjacent_key(word[pos])  # Use a neighboring key\n",
    "        return word[:pos] + random_char + word[pos + 1:]\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: hello\n",
      "Swapped: helol\n",
      "Deleted: helo\n",
      "Inserted: herllo\n",
      "Replaced: helll\n"
     ]
    }
   ],
   "source": [
    "test_word = \"hello\"\n",
    "\n",
    "print(\"Original:\", test_word)\n",
    "print(\"Swapped:\", swap_characters(test_word))\n",
    "print(\"Deleted:\", delete_character(test_word))\n",
    "print(\"Inserted:\", insert_character(test_word))\n",
    "print(\"Replaced:\", replace_character(test_word))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
